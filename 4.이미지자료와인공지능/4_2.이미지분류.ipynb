{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_2.이미지분류.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO/DOS61DDNE330sHlnwjpg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwanys2/AI-math/blob/main/4.%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%9E%90%EB%A3%8C%EC%99%80%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/4_2.%EC%9D%B4%EB%AF%B8%EC%A7%80%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이미지 분류\n",
        "이미지 분류하는 인공지능을 만들어 보겠습니다.  \n",
        "이를 위해서는 많은 종류의 사진이 필요 합니다.  \n",
        "2-1에서 했던 파일을 이용하여 자료를 수집해보겠습니다.  \n",
        "[이미지 자료 수집 프로그램](https://colab.research.google.com/github/hwanys2/AI-math/blob/main/2.자료의수집/2_1.이미지자료수집하기.ipynb)\n",
        "위 링크의 마지막 셀을 이용하여 분류를 위한 이미지를 다운로드 받아보겠습니다.  \n",
        "사실 잘 작동되는 모델을 만들기 위해서는 많은 이미지를 수집하는 것 뿐만 아니라 수집된 이미지의 전처리 작업도 필요합니다.  \n",
        "하지만 이미지의 전처리 작업은 생략하고 진행하도록 하겠습니다.  \n",
        "### 고양이상, 강아지상을 구분하는 프로그램을 만들어보겠습니다.  \n",
        "그런다고 해서 고양이와 강아지를 가지고오는 것은 다소 부적합합니다.  \n",
        "고양이상으로 분류되는 연예인과 강아지상으로 분류되는 연예인의 사진을 학습시키는 것이 보다 적합한 모델 학습 방법입니다.  \n",
        "다음과 같은 연예인 사진을 받아보도록 하겠습니다.  \n",
        "> 1. 고양이상(여자)\n",
        " - 한예슬\n",
        " - 고아라\n",
        " - 신민아\n",
        "2. 강아지상(여자)\n",
        " - 한지민\n",
        " - 이민정\n",
        " - 김태희\n",
        "3. 고양이상(남자)\n",
        " - 김수현\n",
        " - 시우민\n",
        " - 강동원\n",
        "4. 강아지상(남자)\n",
        " - 박보검\n",
        " - 강다니엘\n",
        " - 임시완\n",
        "\n",
        "각 50장의 사진을 다운로드 받아보도록 하겠습니다.\n",
        "\n",
        "이미 다운로드 하여 압축해 놓았습니다. 다음 링크를 이용하세요.  \n",
        "[파일다운로드](https://drive.google.com/file/d/1603GYgaNxe7H0tFxWTFgBA_dwjv0IDda/view?usp=sharing)  \n",
        "이 자료를 티처블머신을 이용하여 이미지 분류 인공지능을 만들어보겠습니다. \n",
        "[티처블머신링크](https://teachablemachine.withgoogle.com)  \n",
        "\n",
        "업로드를 통해 이미지 모델을 학습시키고나면 다음과 같은 소스코드와 파일을 다운받을 수 있습니다.  \n",
        "소스코드\n",
        "\n",
        "\n",
        "```\n",
        "from keras.models import load_model\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "model = load_model('keras_model.h5')\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "# Replace this with the path to your image\n",
        "image = Image.open('<IMAGE_PATH>')\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "print(prediction)\n",
        "```\n",
        "\n",
        "다운로드 받아지는 파일은 다음에서 동일하게 다운로드 받을 수 있습니다.  \n",
        "[모델파일 다운로드](https://drive.google.com/file/d/161W4GLmEDF-ZXnzn2DTOkUm85ZV-gP2o/view?usp=sharing)  \n",
        "이 파일을 왼쪽 폴더모양을 클릭하여 업로드 해줍니다.  \n",
        "그리고 위의 코드를 아래에 그대로 가져다 붙여서 필요한 부분만 수정해보겠습니다.  \n",
        "수정한 곳은 #########################표시를 해두었습니다."
      ],
      "metadata": {
        "id": "WY0Yu3W7L8Ym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xnzye66I67q"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "######다운로드 받은 파일을 연결시키는 부분이라 파일 경로를 지정하기 위해 수정이 필요합니다.######\n",
        "model = load_model('/content/keras_model.h5')\n",
        "############################################################################\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "# Replace this with the path to your image\n",
        "\n",
        "########## 판독할 이미지 위치가 필요합니다. 파일을 하나 올리고 경로 복사할 수도 있지만\n",
        "########## 인터넷의 이미지를 불러와 보겠습니다.\n",
        "########## 아래 url에 판독하고 싶은 이미지의 주소를 넣으면됩니다.\n",
        "import requests\n",
        "from io import BytesIO\n",
        "url = 'https://search.pstatic.net/common/?src=http%3A%2F%2Fimgnews.naver.net%2Fimage%2F119%2F2016%2F10%2F25%2Fnews_1477353741_594983_m_1_99_20161025090303.jpg&type=a340'\n",
        "response = requests.get(url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "############################################################################\n",
        "\n",
        "\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "print(prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[[9.9995160e-01 4.8345872e-05 1.8410301e-09 8.2484262e-12]]  \n",
        "이러한 결과가 출력되었습니다.\n",
        "이는 각 클래스별 확률을 나타냅니다. 현재 첫 번째 사진이99퍼센트로 고양이상여자로 분류하였습니다.  \n",
        "이제 이처럼 보다 쉽게 읽어 올 수 있도록 프로그램을 수정해보도록 하겠습니다.  \n",
        "모델 생성시 labels.txt 파일이 함께 있었습니다.  \n",
        "이를 딕셔너리로 변환하여 사용하겠습니다.  \n",
        "또한 [[9.9995160e-01 4.8345872e-05 1.8410301e-09 8.2484262e-12]] 이자료의 최대값을 가지는 인덱스를 찾기 위해 argmax()라는 명령어를 사용합니다. "
      ],
      "metadata": {
        "id": "sUAzRF57gqtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "######다운로드 받은 파일을 연결시키는 부분이라 파일 경로를 지정하기 위해 수정이 필요합니다.######\n",
        "model = load_model('/content/keras_model.h5')\n",
        "############################################################################\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "# Replace this with the path to your image\n",
        "\n",
        "########## 판독할 이미지 위치가 필요합니다. 파일을 하나 올리고 경로 복사할 수도 있지만\n",
        "########## 인터넷의 이미지를 불러와 보겠습니다.\n",
        "########## 아래 url에 판독하고 싶은 이미지의 주소를 넣으면됩니다.\n",
        "import requests\n",
        "from io import BytesIO\n",
        "url = 'https://search.pstatic.net/common/?src=http%3A%2F%2Fimgnews.naver.net%2Fimage%2F109%2F2021%2F07%2F18%2F0004443363_003_20210718105707416.jpg&type=a340'\n",
        "response = requests.get(url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "############################################################################\n",
        "\n",
        "\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "#################     딕셔너리로 만들겠습니다.   #################################\n",
        "label_dict = {0 : '고양이상 여자', 1 : '강아지상 여자', 2 : '고양이상 남자', 3 : '강아지상 남자'}\n",
        "############################################################################\n",
        "\n",
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "\n",
        "#################  가장 높은 확률의 익덱스를 찾아 해당 결과로 프린트합니다. #############\n",
        "label = prediction[0].argmax()    \n",
        "name = label_dict[label]\n",
        "print(f'당신이 제공한 사진은 {name} 사진입니다.')\n",
        "############################################################################\n"
      ],
      "metadata": {
        "id": "XXpWDPm5fuUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KQ8Kf7Q9ikXs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}